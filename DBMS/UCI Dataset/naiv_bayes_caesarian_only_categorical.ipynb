{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Caesarian\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('caesarian.csv')\n",
    "target = data.columns[-1]\n",
    "print(target)\n",
    "\n",
    "# P(y|X) = P(X|y) * P(y) / P(X)\n",
    "\n",
    "# naive bayes classifier for multiple instances of features\n",
    "def prior_probability(df, y):              # P(y)\n",
    "      \n",
    "    rows = len(df)\n",
    "    values = df[y].value_counts()\n",
    "    prior = []\n",
    "\n",
    "    for i in values:\n",
    "        prob = i/rows\n",
    "        prior.append(prob)\n",
    "        \n",
    "    return prior     \n",
    "\n",
    "def training(df, className):\n",
    "    feature_prob_given_true = []\n",
    "    feature_prob_given_false = []\n",
    "\n",
    "    features = df.columns[1:-1]                 # load all features except class label\n",
    "    class_count = df[className].value_counts()  # count of each class label (eg. yes = 100, no = 200)\n",
    "    class_values = df[className].unique()       # unique class labels (Yes/No)\n",
    "\n",
    "    for feature in features:\n",
    "        distinct_values = df[feature].unique()\n",
    "        f_ls = []\n",
    "        t_ls = []\n",
    "        for value in distinct_values:\n",
    "            true_count = 0\n",
    "            false_count = 0\n",
    "\n",
    "            for i, row in df.iterrows():\n",
    "                if row[className] == class_values[0] and row[feature] == value:\n",
    "                    true_count += 1\n",
    "                elif row[className] == class_values[1] and row[feature] == value:\n",
    "                    false_count += 1\n",
    "            \n",
    "            prob_true = true_count / class_count[class_values[0]]\n",
    "            prob_false = false_count / class_count[class_values[1]]\n",
    "\n",
    "            \n",
    "            t_ls.append({value: prob_true})\n",
    "            f_ls.append({value: prob_false})\n",
    "            \n",
    "        feature_prob_given_true.append(t_ls)\n",
    "        feature_prob_given_false.append(f_ls)\n",
    "        \n",
    "    return feature_prob_given_true, feature_prob_given_false\n",
    "\n",
    "def naive_bayes_classifer(df, X_test, Y_test): \n",
    "     \n",
    "    class_values = df[Y_test].unique()\n",
    "    mle_given_True, mle_given_false = training(df, Y_test)   \n",
    "\n",
    "    # Testing Starts...\n",
    "\n",
    "    descision = []\n",
    "    for each_test_case in X_test:\n",
    "        posterior_T = 1\n",
    "        posterior_F = 1\n",
    "       \n",
    "        for index, feature in enumerate(each_test_case, 0):\n",
    "            \n",
    "            feature_values = mle_given_True[index]\n",
    "            posterior_T *= [i[feature] for i in feature_values if feature in i][0]\n",
    "            \n",
    "            feature_values = mle_given_false[index]\n",
    "            posterior_F *= [i[feature] for i in feature_values if feature in i][0]\n",
    "\n",
    "        posterior_T *= prior_probability(data, Y_test)[0]\n",
    "        posterior_F *= prior_probability(data, Y_test)[1]\n",
    "    \n",
    "        descision.append(class_values[0] if posterior_T > posterior_F else class_values[1])\n",
    "        \n",
    "    return descision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0] \n",
      "Actual:  [1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=.2)\n",
    "\n",
    "X_test = test.iloc[:,1:-1].values\n",
    "Y_test = test.iloc[:,-1].values\n",
    "Y_pred = naive_bayes_classifer(data, X_test=X_test, Y_test=target)\n",
    "print(\"Predicted: \",Y_pred, \"\\nActual: \", Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  9  TN:  4  FP:  0  FN:  3\n",
      "[[4 0]\n",
      " [3 9]]\n",
      "Accuracy Score:  81.25 %\n"
     ]
    }
   ],
   "source": [
    "# manual calculation on Accuracy score and Confusion matrix\n",
    "\n",
    "TP = 0  # Prediction (+) , Actual(+) \n",
    "FP = 0  # Prediction (+) , Actual(-) \n",
    "TN = 0  # Prediction (-) , Actual(-) \n",
    "FN = 0  # Prediction (-) , Actual(+)\n",
    "\n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i] == 1 and Y_test[i] == 1:\n",
    "        TP+=1\n",
    "    elif Y_pred[i] == 1 and Y_test[i] == 0:\n",
    "        FP+=1\n",
    "    elif Y_pred[i] == 0 and Y_test[i] == 0:\n",
    "        TN+=1\n",
    "    elif Y_pred[i] == 0 and Y_test[i] == 1:\n",
    "        FN+=1\n",
    "        \n",
    "print(\"TP: \", TP, \" TN: \", TN, \" FP: \", FP, \" FN: \", FN)\n",
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "CF = np.zeros(shape=(2,2),dtype=int)\n",
    "CF[0,0] = TN\n",
    "CF[0,1] = FP\n",
    "CF[1,0] = FN\n",
    "CF[1,1] = TP\n",
    "print(CF)\n",
    "print(\"Accuracy Score: \", accuracy*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[4 0]\n",
      " [3 9]]\n",
      "Accuracy:  81.25 %\n"
     ]
    }
   ],
   "source": [
    "# Library Based Model Train and Accuracy, Confusion Matrix Calculation\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, f1_score , accuracy_score\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(train.iloc[:,1:-1], train.iloc[:,-1])\n",
    "Y_pred2 = model.predict(test.iloc[:,1:-1])\n",
    "# print(Y_pred)\n",
    "\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(Y_test, Y_pred2))\n",
    "print(\"Accuracy: \",accuracy_score(Y_test, Y_pred2)*100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
