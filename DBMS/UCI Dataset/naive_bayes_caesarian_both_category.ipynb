{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from math import sqrt, exp, pi\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Caesarian\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('caesarian.csv')\n",
    "target = data.columns[-1]\n",
    "print(target)\n",
    "# print(data.columns.get_loc('Delivery Time'))\n",
    "\n",
    "\n",
    "# naive bayes classifi\n",
    "\n",
    "# Calculate the mean of a list of numbers\n",
    "def mean(numbers: list):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers: list):\n",
    "\tavg = mean(numbers)\n",
    "\tvariance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
    "\treturn sqrt(variance)\n",
    "\n",
    "# Calculate the Gaussian probability distribution function for x\n",
    "def calculate_probability(x, mean, stdev):\n",
    "\texponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "\treturn (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
    "\n",
    "\n",
    "def prior_probability(df, target):\n",
    "      \n",
    "    rows = len(df)\n",
    "    values = df[target].value_counts()\n",
    "    prior = []\n",
    "\n",
    "    for i in values:\n",
    "        prob = i/rows\n",
    "        prior.append(prob)\n",
    "        \n",
    "    return prior     \n",
    "\n",
    "\n",
    "def training(df, className, CategoryIndices):\n",
    "    feature_prob_given_true = []\n",
    "    feature_prob_given_false = []\n",
    "\n",
    "    features = df.columns[:-1]                 # Age, Delivery Number, Delivery Time, Blood Pressure, Heart Problem, Caesarian\n",
    "    class_count = df[className].value_counts()  # 2\n",
    "    class_values = df[className].unique()       # 0, 1\n",
    "\n",
    "    id = 0\n",
    "    for feature in features:\n",
    "        \n",
    "        if id in CategoryIndices:\n",
    "            true_count = []\n",
    "            false_count = []\n",
    "\n",
    "            for i, row in df.iterrows():\n",
    "                if row[className] == class_values[0]: true_count.append(df[feature][i])\n",
    "                elif row[className] == class_values[1]: false_count.append(df[feature][i])\n",
    "            \n",
    "            true_mean = mean(true_count)\n",
    "            false_mean = mean(false_count)\n",
    "            \n",
    "            true_std = stdev(true_count)\n",
    "            false_std = stdev(false_count)\n",
    "            \n",
    "            feature_prob_given_true.append({'m': true_mean, 'std': true_std})\n",
    "            feature_prob_given_false.append({'m': false_mean, 'std': false_std})\n",
    "        else: \n",
    "            \n",
    "            distinct_values = df[feature].unique()  # 22, 26, 31 => Age[Categorical], 0,1 => Delivery Number[Numerical]\n",
    "            \n",
    "            f_ls = []\n",
    "            t_ls = []\n",
    "            for value in distinct_values:           # iterate over each of Numerical Value\n",
    "                true_count = 0\n",
    "                false_count = 0\n",
    "\n",
    "                for i, row in df.iterrows():\n",
    "                    if row[className] == class_values[0] and row[feature] == value:\n",
    "                        true_count += 1\n",
    "                    elif row[className] == class_values[1] and row[feature] == value:\n",
    "                        false_count += 1\n",
    "                \n",
    "                prob_true = true_count / class_count[class_values[0]]\n",
    "                prob_false = false_count / class_count[class_values[1]]\n",
    "\n",
    "                \n",
    "                t_ls.append({value: prob_true})\n",
    "                f_ls.append({value: prob_false})\n",
    "                \n",
    "            feature_prob_given_true.append(t_ls)\n",
    "            feature_prob_given_false.append(f_ls)\n",
    "        \n",
    "        id+=1\n",
    "    return feature_prob_given_true, feature_prob_given_false\n",
    "\n",
    "\n",
    "def naive_bayes_classifer(df, X_test, Y_test, CategoryIndices: list): \n",
    "     \n",
    "    mle_given_True, mle_given_false = training(df, Y_test, CategoryIndices)   \n",
    "    # print(mle_given_True)\n",
    "    # print(mle_given_false)\n",
    "    # Testing Starts...\n",
    "\n",
    "    class_values = df[Y_test].unique()\n",
    "    descision = []\n",
    "\n",
    "    for each_test_case in X_test:\n",
    "        posterior_T = 1\n",
    "        posterior_F = 1\n",
    "       \n",
    "        for index, feature in enumerate(each_test_case, 0):\n",
    "            # print(index, feature)\n",
    "            tfeature_values = mle_given_True[index]\n",
    "            ffeature_values = mle_given_false[index]\n",
    "            \n",
    "            if index in CategoryIndices:\n",
    "                posterior_T *= calculate_probability(feature, tfeature_values['m'], tfeature_values['std'])\n",
    "                posterior_F *= calculate_probability(feature, ffeature_values['m'], ffeature_values['std'])\n",
    "                \n",
    "            else:\n",
    "                posterior_T *= [i[feature] for i in tfeature_values if feature in i][0]\n",
    "                posterior_F *= [i[feature] for i in ffeature_values if feature in i][0]\n",
    "\n",
    "        posterior_T *= prior_probability(data, Y_test)[0]\n",
    "        posterior_F *= prior_probability(data, Y_test)[1]\n",
    "    \n",
    "        descision.append(class_values[0] if posterior_T > posterior_F else class_values[1])\n",
    "        \n",
    "    return descision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0] [1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=.2)\n",
    "\n",
    "X_test = test.iloc[:,:-1].values\n",
    "Y_test = test.iloc[:,-1].values\n",
    "# category = [data.columns.get_loc(col) for col in data.columns[:-1]]\n",
    "category = [0]\n",
    "\n",
    "Y_pred = naive_bayes_classifer(df=train, X_test=X_test, Y_test=target, CategoryIndices=category)\n",
    "print(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [5 7]]\n",
      "TP:  7  TN:  2  FP:  2  FN:  5\n",
      "Accuracy Score:  0.5625\n"
     ]
    }
   ],
   "source": [
    "# manual calculation on Accuracy score and Confusion matrix\n",
    "\n",
    "TP = 0  # Prediction (+) , Actual(+) \n",
    "FP = 0  # Prediction (+) , Actual(-) \n",
    "TN = 0  # Prediction (-) , Actual(-) \n",
    "FN = 0  # Prediction (-) , Actual(+)\n",
    "\n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i] == 1 and Y_test[i] == 1:\n",
    "        TP+=1\n",
    "    elif Y_pred[i] == 1 and Y_test[i] == 0:\n",
    "        FP+=1\n",
    "    elif Y_pred[i] == 0 and Y_test[i] == 0:\n",
    "        TN+=1\n",
    "    elif Y_pred[i] == 0 and Y_test[i] == 1:\n",
    "        FN+=1\n",
    "        \n",
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "CF = np.zeros(shape=(2,2),dtype=int)\n",
    "CF[0,0] = TN\n",
    "CF[0,1] = FP\n",
    "CF[1,0] = FN\n",
    "CF[1,1] = TP\n",
    "print(CF)\n",
    "print(\"TP: \", TP, \" TN: \", TN, \" FP: \", FP, \" FN: \", FN)\n",
    "print(\"Accuracy Score: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[1 3]\n",
      " [4 8]]\n",
      "Accuracy:  0.5625\n"
     ]
    }
   ],
   "source": [
    "# Library Based Model Train and Accuracy, Confusion Matrix Calculation\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, f1_score , accuracy_score\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(train.iloc[:,:-1], train.iloc[:,-1])\n",
    "Y_pred2 = model.predict(test.iloc[:,:-1])\n",
    "# print(Y_pred)\n",
    "\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(Y_test, Y_pred2))\n",
    "print(\"Accuracy: \",accuracy_score(Y_test, Y_pred2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
